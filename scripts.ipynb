{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Dict, Any, Optional\n",
    "import psycopg2.extras\n",
    "import psycopg2\n",
    "import json\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(file_path: str, file_name: str, limit=100):\n",
    "\n",
    "    sample_path = os.path.join(file_path, f\"sample_{limit}\")\n",
    "    if os.path.exists(sample_path) == False:\n",
    "        os.mkdir(sample_path)\n",
    "\n",
    "    with open(os.path.join(file_path, file_name)) as file:\n",
    "        sample_lines = [next(file) for x in range(limit)]\n",
    "\n",
    "    with open(os.path.join(sample_path, file_name), \"a\") as file_sample:\n",
    "        file_sample.writelines(sample_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','conversations.jsonl', 100000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','conversations.jsonl', 10000)\n",
    "sample('C:/Users/Krips/Documents/Programming/PDT/','conversations.jsonl', 1000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','conversations.jsonl', 1000000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','authors.jsonl', 100000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','authors.jsonl', 10000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','authors.jsonl', 1000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','authors.jsonl', 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv_value(value: Optional[Any]):\n",
    "    return (\n",
    "        str(value)\n",
    "        .replace('\\n', '\\\\n')\n",
    "        .replace('\\t', '\\\\t')\n",
    "        .replace('\\r', '\\\\r')\n",
    "        .replace('\\x00', '')\n",
    "        .replace('\\\\', '\\\\\\\\')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor:\n",
    "    @staticmethod\n",
    "    def generate_author_row(_input: dict = {}):\n",
    "        return {\n",
    "            \"id\": _input.get(\"id\", r'\\N'),\n",
    "            \"name\": _input.get(\"name\", r'\\N'),\n",
    "            \"username\": _input.get(\"username\", r'\\N'),\n",
    "            \"description\": _input.get(\"description\", r'\\N'),\n",
    "            \"followers_count\": _input.get(\"public_metrics.followers_count\", r'\\N'),\n",
    "            \"following_count\": _input.get(\"public_metrics.following_count\", r'\\N'),\n",
    "            \"tweet_count\": _input.get(\"public_metrics.tweet_count\", r'\\N'),\n",
    "            \"listed_count\": _input.get(\"public_metrics.listed_count\", r'\\N'),\n",
    "        }\n",
    "\n",
    "\n",
    "class PostgreClient:\n",
    "    @staticmethod\n",
    "    def create_author_table(cursor) -> None:\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            DROP TABLE IF EXISTS authors;\n",
    "            CREATE UNLOGGED TABLE authors (\n",
    "                id                  bigint PRIMARY KEY,\n",
    "                name                VARCHAR ( 255 ),\n",
    "                username            VARCHAR ( 255 ),\n",
    "                description         text,\n",
    "                followers_count     integer,\n",
    "                following_count     integer,\n",
    "                tweet_count         integer,\n",
    "                listed_count        integer\n",
    "            );\n",
    "        \"\"\"\n",
    "        )\n",
    "            \n",
    "    def copy_stringio(connection, authors: Iterator[Dict[str, Any]]) -> None:\n",
    "        with connection.cursor() as cursor:\n",
    "            csv_file_like_object = io.StringIO()\n",
    "            for author in authors:\n",
    "                csv_file_like_object.write('\\t'.join((\n",
    "                    author[\"id\"],\n",
    "                    clean_csv_value(author[\"name\"]),\n",
    "                    clean_csv_value(author[\"username\"]),\n",
    "                    clean_csv_value(author[\"description\"]),\n",
    "                    author[\"followers_count\"],\n",
    "                    author[\"following_count\"],\n",
    "                    author[\"tweet_count\"],\n",
    "                    author[\"listed_count\"],\n",
    "                )) + '\\n')\n",
    "            csv_file_like_object.seek(0)\n",
    "            cursor.copy_from(csv_file_like_object, 'authors', sep='\\t')\n",
    "            connection.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "# import asyncio\n",
    "import threading, queue\n",
    "\n",
    "\n",
    "def author_row_traverse(file_path: str, file_name: str):\n",
    "    unique = {}\n",
    "    duplicates = set()\n",
    "    block_entries = []\n",
    "\n",
    "    block_size = 0\n",
    "    batch_size = 0\n",
    "\n",
    "    import_start_time = datetime.now()\n",
    "    block_start_time = datetime.now()\n",
    "\n",
    "    connection = psycopg2.connect(\n",
    "        dbname=\"PDT\",\n",
    "        user=\"postgres\",\n",
    "        password=\"291122\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "    )\n",
    "    # connection.autocommit = True\n",
    "\n",
    "    with connection.cursor() as cursor:\n",
    "        PostgreClient.create_author_table(cursor)\n",
    "        connection.commit()\n",
    "\n",
    "    with open(os.path.join(file_path, file_name), encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            batch_size += 1\n",
    "\n",
    "            _json_file = json.loads(line)\n",
    "            if _json_file.get(\"id\", \"None\") in unique:\n",
    "                duplicates.add(_json_file.get(\"id\"))\n",
    "            else:\n",
    "                unique[_json_file.get(\"id\")] = True\n",
    "                block_entries.append(Extractor.generate_author_row(_json_file))\n",
    "\n",
    "            if batch_size == 10_000:\n",
    "                block_end_time = datetime.now()\n",
    "                _time_delta = block_end_time - block_start_time\n",
    "                print(\"-\")\n",
    "                print(f\"time now: {block_end_time.isoformat()}\")\n",
    "                print(\n",
    "                    f\"block excecution time: {int(_time_delta.seconds/60)}:{int(_time_delta.seconds % 60)}\"\n",
    "                )\n",
    "                block_start_time = block_end_time\n",
    "                batch_size = 0\n",
    "                block_size += 1\n",
    "                if block_size == 10:\n",
    "                    PostgreClient.copy_stringio(connection, block_entries)\n",
    "                    block_entries = []\n",
    "                    block_size = 0\n",
    "\n",
    "    import_end_time = datetime.now()\n",
    "    _time_delta = import_end_time - import_start_time\n",
    "    print(\n",
    "        f\"import excecution time: {int(_time_delta.seconds/60)}:{int(_time_delta.seconds % 60)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author_row_traverse('C:/Users/Krips/Documents/Programming/PDT/sample_10000/', 'authors.jsonl', block_max_size=1_000)\n",
    "author_row_traverse('C:/Users/Krips/Documents/Programming/PDT/', 'authors.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "\n",
    "# conn = psycopg2.connect(\n",
    "#     dbname='PDT',\n",
    "#     user='postgres',\n",
    "#     password='291122',\n",
    "#     host='localhost',\n",
    "#     port='5432'\n",
    "# )\n",
    "# with conn.cursor() as cursor:\n",
    "#     cursor.execute(Extractor.create_author_table())\n",
    "#     conn.commit()\n",
    "#     # cursor.execute(\"SELECT * FROM authors\")\n",
    "#     # print(cursor.fetchone())\n",
    "    \n",
    "#     cursor.close()\n",
    "#     # commit the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(_dict):\n",
    "    _dict['key2'] = 1\n",
    "    _dict['key4'] = 1\n",
    "    \n",
    "def func1(_dict):\n",
    "    \n",
    "    _dict['key1'] = 1\n",
    "    func2(_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    _dict = {}\n",
    "    func1(_dict)\n",
    "    print(_dict)\n",
    "    print('key1' not in _dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "nums = [1,2,3,4,5,6,7,8,9,10]*1000000\n",
    "\n",
    "def f(x):\n",
    "    return x * x\n",
    "def main():\n",
    "    # Make sure the map and function are working\n",
    "    print([val for val in map(f, nums)])\n",
    "\n",
    "    # Test to make sure concurrent map is working\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        print([val for val in executor.map(f, nums)])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import psutil\n",
    "import time\n",
    "nums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]*100\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    result = 1\n",
    "    time.sleep(1)\n",
    "    for i in x:\n",
    "        result += i\n",
    "    return result\n",
    "\n",
    "def f(x):\n",
    "    result = 1\n",
    "    time.sleep(10)\n",
    "    for i in x:\n",
    "        result += i\n",
    "    return result\n",
    "\n",
    "\n",
    "def spawn():\n",
    "    procs = list()\n",
    "    n_cpus = psutil.cpu_count() - 6 - 8\n",
    "    print(n_cpus)\n",
    "    for cpu in range(n_cpus/2):\n",
    "        affinity = [cpu]\n",
    "        d = dict(affinity=affinity)\n",
    "        p = mp.Process(target=run_child, kwargs=d)\n",
    "        p.start()\n",
    "        procs.append(p)\n",
    "    for cpu in range(n_cpus/2):\n",
    "        affinity = [cpu]\n",
    "        d = dict(affinity=affinity)\n",
    "        p = mp.Process(target=run_child, kwargs=d)\n",
    "        p.start()\n",
    "        procs.append(p)\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "        print('joined')\n",
    "\n",
    "\n",
    "def run_child(affinity):\n",
    "    proc = psutil.Process()  # get self pid\n",
    "    print(f'PID: {proc.pid}')\n",
    "    aff = proc.cpu_affinity()\n",
    "    print(f'Affinity before: {aff}')\n",
    "    proc.cpu_affinity(affinity)\n",
    "    aff = proc.cpu_affinity()\n",
    "    print(f'Affinity after: {aff}')\n",
    "    print(f(nums))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    spawn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _row(i):\n",
    "    if i % 2 == 0:\n",
    "        print('x1')\n",
    "        yield {f'id{i}':2}\n",
    "    else:\n",
    "        print('x2')\n",
    "        yield {f'id{i}':1}\n",
    "\n",
    "i = 0\n",
    "rows = []\n",
    "for x in range(6):\n",
    "    rows.extend(_row(x))\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "_rows = [row for row in filter(lambda x: x is not None, rows)]\n",
    "print(_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(['PDT','pdt','pdT','Pdt','pDT','PDt','PdT','PDT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "\n",
    "a = [{'id':1},{'id':3},{'id':4},{'id':5},{'id':6}]\n",
    "# print(functools.reduce(operator.iconcat, a, []))\n",
    "\n",
    "print(a)\n",
    "# _dict = {'id':1}\n",
    "# print(_dict)\n",
    "# _dict['id'] = 2\n",
    "# print(_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(str('https:/twitter.com/foldingchable/status/1498419411711102981?s=12##Der+5.+Tag+der+%23russianinvasion')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
