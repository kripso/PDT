{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def sample(file_path: str, file_name: str, limit = 100):\n",
    "    \n",
    "    sample_path = os.path.join(file_path, f'sample_{limit}')\n",
    "    if os.path.exists(sample_path) == False:\n",
    "        os.mkdir(sample_path)\n",
    "\n",
    "    with open(os.path.join(file_path, file_name)) as file:\n",
    "        sample_lines = [next(file) for x in range(limit)]\n",
    "\n",
    "    with open(os.path.join(sample_path, file_name), 'a') as file_sample:\n",
    "        file_sample.writelines(sample_lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','conversations.jsonl', 100000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','conversations.jsonl', 10000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','conversations.jsonl', 1000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','authors.jsonl', 100000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','authors.jsonl', 10000)\n",
    "# sample('C:/Users/Krips/Documents/Programming/PDT/','authors.jsonl', 1000)\n",
    "sample('C:/Users/Krips/Documents/Programming/PDT/','authors.jsonl', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "def row_traverse(file_path: str, file_name: str, limit=1_000_000):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    unique = {}\n",
    "    duplicates = set()\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    with open(os.path.join(file_path, file_name)) as file:\n",
    "        for line in file:\n",
    "            count += 1\n",
    "            _json_file = json.loads(line)\n",
    "            if _json_file.get(\"conversation_id\", \"None\") in unique:\n",
    "                duplicates.add(_json_file.get(\"conversation_id\"))\n",
    "            else:\n",
    "                unique[_json_file.get(\"conversation_id\")] = 1\n",
    "\n",
    "            if count % 1_000_000 == 0:\n",
    "                print(\n",
    "                    \"-\"\n",
    "                    * (\n",
    "                        len(datetime.now().isoformat()) + 6\n",
    "                        if len(datetime.now().isoformat()) > len(str(count))\n",
    "                        else len(str(count))\n",
    "                    )\n",
    "                )\n",
    "                print(f\"time: {datetime.now().isoformat()}\")\n",
    "                print(count)\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    print(f\"time to complete: {end_time-start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_time = 0\n",
    "for i in range(100):\n",
    "    _time = row_traverse('C:/Users/Krips/Documents/Programming/PDT/sample_10000/','conversations.jsonl')\n",
    "    result_time += _time\n",
    "     \n",
    "print(result_time/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor:\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_author_row(_input:dict = {}):\n",
    "        return {\n",
    "            'id': _input.get('id'),\n",
    "            'name': _input.get('name'),\n",
    "            'username': _input.get('username'),\n",
    "            'description': _input.get('description'),\n",
    "            'followers_count': _input.get('public_metrics.followers_count'),\n",
    "            'following_count': _input.get('public_metrics.following_count'),\n",
    "            'tweet_count': _input.get('public_metrics.tweet_count'),\n",
    "            'listed_count': _input.get('public_metrics.listed_count'),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def create_author_table():\n",
    "        return ''' \n",
    "            CREATE TABLE authors (\n",
    "                id bigint PRIMARY KEY,\n",
    "                name VARCHAR ( 255 ),\n",
    "                username VARCHAR ( 255 ),\n",
    "                description text,\n",
    "                followers_count integer,\n",
    "                following_count integer,\n",
    "                tweet_count integer,\n",
    "                listed_count integer\n",
    "            );\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import asyncio\n",
    "import threading, queue\n",
    "\n",
    "def write_to_csv(writer, row):\n",
    "    writer.writerow(row)\n",
    "\n",
    "\n",
    "def author_row_traverse(file_path: str, file_name: str, block_max_size=10_000):\n",
    "    unique = {}\n",
    "    duplicates = set()\n",
    "    \n",
    "    block_size = 0\n",
    "\n",
    "    import_start_time = datetime.now()\n",
    "    block_start_time = datetime.now()\n",
    "    with open(os.path.join(file_path, Path(file_name).with_suffix('.csv')), 'w', encoding=\"utf-8\", newline='') as f:\n",
    "        writer = csv.writer(f, escapechar='\\\\')\n",
    "        writer.writerow(Extractor.generate_author_row().keys())\n",
    "\n",
    "        with open(os.path.join(file_path, file_name), encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                block_size += 1\n",
    "        \n",
    "                _json_file = json.loads(line)        \n",
    "                if _json_file.get(\"id\", \"None\") in unique:\n",
    "                    duplicates.add(_json_file.get(\"id\"))\n",
    "                else:\n",
    "                    unique[_json_file.get(\"id\")] = 1\n",
    "                    writer.writerow(Extractor.generate_author_row(_json_file).values())\n",
    "                    \n",
    "                if block_size == block_max_size:\n",
    "                    block_end_time = datetime.now()\n",
    "                    _time_delta = (block_end_time-block_start_time)\n",
    "                    print(\"-\" * 50)\n",
    "                    print(f\"time now: {block_end_time.isoformat()}\")\n",
    "                    print(f\"block excecution time: {int(_time_delta.seconds/60)}:{int(_time_delta.seconds % 60)}\")\n",
    "                    block_start_time = block_end_time\n",
    "                    block_size = 0\n",
    "\n",
    "    import_end_time = datetime.now()\n",
    "    _time_delta = (import_end_time-import_start_time)\n",
    "    print(f\"import excecution time: {int(_time_delta.seconds/60)}:{int(_time_delta.seconds % 60)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author_row_traverse('C:/Users/Krips/Documents/Programming/PDT/sample_10/', 'authors.jsonl', block_max_size=100)\n",
    "author_row_traverse('C:/Users/Krips/Documents/Programming/PDT/', 'authors.jsonl', block_max_size=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname='PDT',\n",
    "    user='postgres',\n",
    "    password='291122',\n",
    "    host='localhost',\n",
    "    port='5432'\n",
    ")\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(Extractor.create_author_table())\n",
    "    conn.commit()\n",
    "    # cursor.execute(\"SELECT * FROM authors\")\n",
    "    # print(cursor.fetchone())\n",
    "    \n",
    "    cursor.close()\n",
    "    # commit the changes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
